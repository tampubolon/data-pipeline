# data-pipeline
Data Pipeline on AWS

![Architecture Diagram](/Pictures/image.png)

The architecture can be also see here: 
[Architecture Diagram](https://viewer.diagrams.net/?tags=%7B%7D&lightbox=1&highlight=0000ff&edit=_blank&layers=1&nav=1&title=Jitera.drawio#R%3Cmxfile%3E%3Cdiagram%20name%3D%22Page-1%22%20id%3D%22_bkS12qFeahq00A4bDJi%22%3E7V1Zc6O4Fv41qbrzEBdIbH70lu5MZ5ssM939ksIGJ0zb4ME4S%2F%2F6K7HYIATIRixOyJ1bbQtZlnW%2Bc3Q2HZ3A0fLti6uvni8dw1ycAMF4O4HjEwBEDUroH9zyHrRoIGx4ci0j7LRruLN%2Bm2GjELZuLMNcJzp6jrPwrFWycebYtjnzEm266zqvyW5zZ5H81pX%2BZKYa7mb6It36j2V4z0ErgFDZPfhqWk%2FP0VcrcvgDl3rUO%2Fwp62fdcF5jTXByAkeu43jBq%2BXbyFzg1YsWJvjcWcbT7cxc0%2FZYPjCWf9w%2BnylT88vvry%2Bbif2%2B%2Fn1zGo7yoi824S8%2BAcoCjTc0rBf08gm%2FjJqmUcMdfDy%2Funm4jx6gL52SnVFbYgh%2FCbz3aGHXv0xvhhdIQE9XjmV7PqXkIfoP%2FY5R8H8ZdR3hlh6QKY20NjXdKKa7oX9E2jeQjbQ2Nd0oprvhd9Gsk420NlVOz5j8tEj5tEh8Gv0Hh87GW1i2OdryBF7juWN7I2fhuP76Q%2FS%2FM4yT4dxaLGLt6mAgigpqX3uu88uMPZn7fxgZ%2BvrZNMJhX0zXsxC%2FXOhTc3HjrC3Pcmz0bOp4nrOMdRgsrCf8wHNWqFUP380QeE30BcNnb7lA78VwpqEkEEH0PkQO%2Fkp9vQp%2B1tx6w%2FMYIs5a4YfLtycshXr661rqueba2bgz83yG5zNEb4NXyV5ruAVnnJMitkBzN99iTSFnfTGdpem576jLVtKFXB7KOTni%2Bted1FC1oOk5Ji%2BiNj2UU0%2FbkXecjF6EzLwHYwM1xXKmgURb%2BNZxvWfnybH1xWTXOnSdjW1sSbvrc%2BFgovnE%2Bdf0vPeQOvrGc5KkM98s73vs9Q88FIJs8G78Fo7sv3mPvbkxXQv9bowEvy0AXyRxQR6NPN19Mr28lQBBR%2Fzzc0npmgvds16Skp9GmPCjN1hq7SCgikkIwAgC0RDBTMNPxQU1MZCsEliS%2B8mBAmCnBhq4rv4e6xZK1ewJC8T3KELuvMj%2BUEj0Ry%2BCGexAu13cw3EMo93zKHGMwOq%2Bf4%2B%2FiY2E3%2B6G8t%2B9x9%2BVYIoAIXnLyso8cj3MoxDyU9PYmKc05kPeYsW8pqj5%2FftSXv%2BKeOQgJe5icDkcDx5HF4O7u%2FOzH50u9%2BF0uckY7Uk7yfHRdbmFvpwaOh99TpZaps8pmTy%2B5dbJi%2BmLoiGypJG0zuFnmlhwO6b%2FGEyvirI6%2FDRMb2LQTwPEc%2BF8SGrfTXO%2BCDsNuAINmNV8VCpRgPfVW6G8n95a0L8aPVSUijepO9M28HIGe9V%2BW1TUsFkhOQCEzWrh6BjkQEAyMHfDK9jLMHF9%2BZfkgZSMI0Xh0jKMgN3MtfVbn24lXHI%2FHFOBmsvsoT87HPJk60Rml2OnQk8QNJBAQQT6ksZaZHCEo5J%2BDmc%2BX5veCSn3eABMbkQUtlWEKYwiDPIWYeX2MwZV9t61np7QmgHhIlDqqbzdXi6WeXIxFAgulspxcTiMWhvXqsUEH%2F%2B4Glxej4fFcSUetgtVv65aK6YoubBnvNv60nk0pmlFHkxUONRQO%2BpuWOZO%2Bbcdm5OuK0tJSb71wsV1XZDWdbXKZIPWrIDfyfQfCZHeci9txGFtkfB9Bj3Qc1yksgnoG3VD99gkPIK1V51wx8BYh2Zryn4OmS7Oo%2Fz4UCJsTgXKPTnFiWIUYIqzIhQqIiIADET86%2B5xfD16uJxcfSKZvf5vnZbW4%2F5AlcRKpTUZWwCylpbWSgScOEj6sDxIvpy%2FzWYDUxpr859%2F%2Fvsy%2FXnz7fZ0C8l6BXaWjCXk32FCF1Ckbl%2F%2BPvlrKL18%2F3NiWt%2F%2BO70YX%2F4TblZNCVmQHfVJ8CccP56dX0xy%2Ba5j2GoYVkuqVxKsk2HpmFWaVbBaZkFH2YjFvF5THLwPCE1AlZNDZMTBedlqgMWFh6TKzfno%2FuF20smQumWIApqXIY2klnFle5mV7aWa2F4h00ykntTf%2FRGxpaqFgMwmBP4%2BH0%2BuOxFQt96viXWKADpCmlEjPnpMkjkrj7tH%2F8BkOjEBzOJkumR%2FSZMJJFYQlATNuBQ7qCYVypa4JiGDfju4HPy8vkKd7iff728HowzXFgGqLh8q0daafChBHGja%2BOSz5ENhF7mrz7w85t7jWIsE1YTIFiPffg3ZUFSN%2FKj8F0zilfozIzdAoYVSjSaQ2rpFgUjQBwIReGA93SIKsJ8cCcKeEPsj5pZx2OUA9YC6fp9SO6gBlzX5y1qGpv4xSSdeKKwBTTW5YTihaV87ShQiI2X3tVwNI%2Frif0bJV31EATBCOsJ%2B3REFILFt3Lxglh2mxGpwAoDKfxsnenAaZGIMUAdRWr0F%2FsLweWZi8Gihr9fWHGnnvtKenxAcfH2GNZcE%2Buuz5Zl3K92n%2FCtStpOg5qFoiwSZxEjxjieAAEoCiMIhASRP5tZCuHuc2AOESWC7HDvtgAAbpl22A58%2F7e7MpW4jixh9aIC2gve1tT5u6ilpE7de6sFGAmyHq3FRlKzYWG3MGUifTiPGXx3rzN36KrfOR2UW1UEf7ofKygX0GZziYbWAnJBv5w8%2FCn94VxTgYFWhr2zTsrfl7GiJ2rU6xKGYYr12b2KsuTeRT6QlQhI24i%2BpY5377VrnZo67168ssNIHcncUlVMWGJLDQmUhN0m0Uxc6deGzqQv0c121qgtRbueHF68a6%2FYHWiVeG8qsbDF9GqteQJ9OM3VVW0yfdvn0onkzqCfEybhOPenUk8%2BlnoCEciJJzSsnAjPz3ozPugqHHc93PF%2BK58XoaFFjHA8yOX690m3OkWpruVmwpIYEX93WADWMAs%2BNBahzag%2Fwp9qtiZbbteynoyaaBBsnWnaUjz%2FRrleetbR%2BHz%2BzyULjdMu2aPjT7XyJL0QCwq05c55s6%2FjJp1HqKNVLvuxiWFXISv9Tx0wxRYa02lf1JmBl2yH8aYZ0YLxc6DNnjrvUc6vitp56KqVads20q3Obu3d1ez1zDCwy8bSBMLGDt0dMQ63xLS%2FKX6uFhmHSMfrMNxMvy5mrL4%2BcgGrjBMyu8VuBANVXgZ4ifDFt0z1%2BnbMvNU0%2FiSEj8FKfPVu2mZHs3fnSOl9a%2B3xpL8tXxKmPs4WzMR4d%2B1HH98Py4GGpFxVqy6v1V6dnTWLI0%2Fm6WSL9hYmBCwkfoygjBgoL7CIUnp0hbUSgEf33xjV7m7U%2FEgcCklaIQLNCJJVWZUmuTAofVd48z6OVuYguLocd9Gu4OpIICUiB%2FOpIZH%2FeV7bQD4o1Ur%2B3vRCjnOCoB2LljvvRZD1JVtsY4AvRd6J2u7GLSeokyZtcXpigXk8QkgXze1CQDqFhJsVSFZ0L81ECnThNiZgYlymqdNRWtoIAlJN6gCiQ20NG0QCWoZIDVXxwW2a4pyUqlaXoS7zF29P1KmloMQXmt5b4xQRXkh9coG%2B9nIzPB6Prq78nt%2FxLy3fh%2F85kORaTxVyYSzQFffG4NA1Ln4XeYj6eB4m45hSo6ZPrtVotMsNdQdv6fLeTb9dfrs7vz30RVGzDtKeUrGv%2B2obXmrj4J0X4FpSml5kzN7GT9uFqhOl%2Bx31v6HaBbhdo3y7AMwksxfxKdMFcY1Kf4cKoyTfE68Lo4uHufnLb%2BZw71j0W1jV%2FcfIxixJxqS8tzldvMdbsPAnWOkNQKA7zUUZJ979xnZm5Xvt5gsKdp89%2BFcQAc6sQfdSb5kQoE5eIpSEEIljV4uRWxEwMlbDteah%2B%2FDxmmYQr9B%2FW5LVSCN%2BzKEj9SPnf229FDkZeUVhYKZjrlbR00DH4tu6u7h6vru%2FPM86ZtNa2XNvNXFMiqn2ROO%2BMaN%2BLDhwXGpa7Vu4yJroGncm0vH64z7yCuNMwOw2zfRomV%2BNQ7RNhyOjKwKaUTK18LhnIUjLv0B6fE71Ipollahalp7EKdNfxJpW8RpsBs8ZTel6WPXf2nMxn0aM1lkNZNEW6X5UirZU%2FJ5IJhAtHNxrgi2X6cvAOgzEMEqJa6lMwSLs0vLK80T4tbzTbrJr59bpn%2BxlTqT0d%2F52dHYWZJWQ4cPa2schdOjVSxckB%2Ff0yTngRWhDEwTESGijiwYSW80eqmtA07avj6K0IVlTC5j2Yp7EvtFmepsXeS5E6K89P0k5KJ%2FodhV9NU5IXu8iy1IMgdrHvwVCB5Lj1QoUWsOugUgYqgLgCWtZkHlARJSCT49YKFTHaCjusVIYVNHASK5ATWFJhn8rBQosGdWDhCZY%2B0CoRLH2g1YwVmsMjGyuh4c2olwKaXoqvgDsKvRSISb1jd33n3qoGMZLcr5vK%2B6kanKg8Gh0Dlck7ww6msij1i4aqms4id8n%2FkRiagUAlaM14ly8%2FWoNqae2fUgpvmtzdLvkj2tj53G6aOpoUP1325fxtNhuY0lib%2F%2Fzz35fpz5tvt8GNm83ZoqR7gaQ6M4DIkZSaTyaJ1DsIOGmJveSJtoqVxMLjbFHqQlvkEEl7SGb3sPswCB8prPliUlHMPmvCKbAsmC%2Bmn2TYdIB5s%2FLro7jmzLReglKK%2B0ypvohzGAk38eLNrUWiukizMyOX7MXSUfcJJvDQtTB3dkFKlkA5%2FQ4MaqhcJPcVflXiAU3b5BosFyx7tfF2MBY8B69lPEt5TWQp51Yl%2BqgA0TRSG6VUP9ruMnF4kPsFR3TQ9FMiX3DfRHdRyYDLw9p042IumZfe3tIsgjCcnPlWVdWlWWCqJqtEESEaBSIqh4xSqiqfLT62dBr8gw8sDQf3o69HlkE81f2s1lQtHlmToXRSkEOcoiuF%2Btm7hQQ1Ip6qRgUdazmZmm23FSSLw8c98obbQ%2Bo1TNN5IshAgtXSOZ0rroH0hfc10zk7gY5ZyEPWooVY6uPfMMPqQI46XnxyKVPl5T9p79kMFRq8TL4CPMKl1OZuMKN9J328OnEp9O9KuWyxT0ncUypSeej7WfZJvsM1HjmFK2G2FTO7Rt8LO5%2Bn8SeW0Yo%2BKnhESMTzKRcL0LRl0k%2FDDzrZuhB3pOA%2FGlJiWGU6LAr2ElafBFmQcMg1j6wqzLCyUIOdUKKUP9XaBp3sG2qag47UG3TgSYNHITPUKNoQLaRRHXgYql83AB4GbfrzgUcm6i4rIF3Iql7wMNRdrh08cgcdiiYtSJB0Qohp9NS7bzEUJujQ0w70ENV4FCntk64XOwy1EzvstAM7KckjyQ2jh%2BXu3Q49LUEPkf4vpKu21oudbEO9tS4gpXMBUYLxkkDIJQS2pgVTG015tTPlqaJJIRxBGiWZo1ZzLOfWW7qkmDvuzDROfTSc6sa%2Fm7UXYGa7ShFScKP7NP0fLn6EXkb%2F%2FBF08hE315fW4j3o%2BtVcvJiYpLHn4dcHw7tLfRF79qK7lo7%2BRfTXvQ2iekG%2Fmb6idFmYHsLT6Xqlz3DSUeq5466e8R1AQUpT0IbReRoCEjdvMRk9s2zDBwR%2BGGVBBU88fCEiWsIluWaI%2Fs5r8mteHddITmw71umrOf1loeHwmAF%2BT0MEJfr5l7P5Y2xXMbyiDb2e6rNfT36a7ylBMSCLAbHiL%2F6I%2FQzDnDlBLZ5T79ma%2FbJxkNb%2FuIWrdkeLR%2FaNkTO3X2w68X5ZW1oo1RgF1GGYLhaQkeDj4YZiulSvpCQiTjkAJa0k0SRRZSFW0EbTXuv2MXp%2BipY8YK%2BoaS2o3n2sjca91vmk6eghnNKw3zR6sguss4KlqDZYVgIT52QllpMD%2B8%2Bl3LkAPj8gkSd%2BxxBm3v9Kow%2FLcFvf6743IPOoxkflOA5XyB9J1crgOFE7D%2BngApbI1mlVUc2AvxM313ys80IlWZkIq4hSOi9YpDmguJwWovMyQ7b%2F%2BMfV4PJ6PDzONHDj3daXzqMxJejKfBtVuXxYARJFJqgHPFSQJrqWc4K1HM2zXdpbgo4urh%2FGZ7fXV8dG7tkuaZt%2BykOpl960sHvNuf8w209YWuKPnNV7C%2FbruILZ%2BGRG46uCb%2B003Pi22CeODKhRYYAYy%2FRrVXCV1OLXenN0sk7D9tn%2BdRpo5WCy7pRO1fwouGQ6d2sprP0QnkNNg4L7rdL0eVZYD7QnSieJcmwKh7u%2F4V50Onz566rhRbC8TFb5S47IXHgDEN4puboif3RcVVioPjhW1%2Fjutj3W1w6Tk1yRD19Xv5x6ui1GEeVm0bxJtLr6lW22UVCqsc1W05LbbU8AHAQ2yN2EOW659e24%2FkfRlqi%2FxzqE6M4U9amqStuSbJlCHPbF3E%2BgF8EsuIpuqXzZlL2PSBvOq70ISqrszh9jO8awXGRHL%2FBCI1t26XvNc90vR19opaTVrWaArLDSSmVxKYnBy7JvgKV0VLPfxcTpJmjqfgJI8dLVGteU2pgb2O%2Bi4kz4kSkp7%2FWip43n%2FEShEz%2F0ohkqKX7SuxetZkZ18GnjST8En076UOFDlsFvHD65%2BYBdZnKXmdxlJu%2FgWJyZjCTfiIPkqz41GQCy0IqcFkW1piZHkfX6LnkzzLm%2BWezoUOzlacwNT6RyAoIIzFXTZfKmuNRQFfvdVZqxVCmVD%2FHmNUZnohr5wVdzyoCkc3X3%2BNHpnG3WlE5SzddQ0v3PqQl4NJ9cZectaQI9CWMOMl3U%2BkmaU47k1qpdqtnGSd6mnS7FVyNYzoiC7x8QJoQRAmWxYZjsa4QU6oLFcAFZBwnMpyCxuRHjtRb6Ex4wIKdzW2slP%2FUez4rJnxX%2FGfsBaeHGWpk4TRK9HLgzTJQZtjGx1RSaq5c6IqG9wSGge3252kyRILM%2FNGykHpmyQTEYaNlfBwAHvXUdTJidSoITRy8dw8Q9%2Fg8%3D%3C%2Fdiagram%3E%3C%2Fmxfile%3E)



## Data Pipeline Architecture Workflow

**1. Human users or machines upload media files to the S3 bucket `S3_INPUT`.**

**2.  Once a file upload is complete, an event is triggered.**

**3. Event Processing**
   - EventBridge routes the event to the Lambda function `LAMBDA_CLASSIFY`.
   - `LAMBDA_CLASSIFY` determines the file type (e.g., document, 3D file, image, or video) and processes the event data to:
     - Forward the event to the appropriate SQS queue.
     - Generate metadata for the uploaded file.

**4. Queue and Metadata Handling**
   - Step 4.A:  
     `LAMBDA_CLASSIFY` forwards the event data to the relevant SQS queue:  
       - Document files → `SQS_DOCUMENT`  
       - Image files → `SQS_PICTURE`  
       - 3D files → `SQS_3D_FILE`  
       - Video files → `SQS_VIDEO`
   - Step 4.B:  
     Metadata for the uploaded file is sent to DynamoDB `DYNAMODB_INPUT`. This step runs in parallel with 4.A.

**5. Job Queue Processing**
   - Files in the SQS queues are processed based on their `processingOption`, which defines the required actions for the uploaded file.  
     Examples:  
     - Document files → Classification, Text Extraction, Semantic Analysis  
     - 3D files → Simulation, Rendering, Render Optimization  
     - Image → Image recognition, Resize, Convert Format
     - Video files → Transcode / Encode, Extract Key Frame, Caption Generation
   - The `processingOption` is an input provided by the user during file upload (Step 1).
   - `LAMBDA_CLASSIFY` forwards this information to the appropriate processing stack along with the S3 file path (`S3_INPUT`). Procesing stack use the S3 file path to download the input file.

**6. File Processing**  
   - The processing stack downloads files from `S3_INPUT` and processes them using AWS services such as:  
     - **Amazon Textract** → Text Extraction  
     - **Amazon Rekognition** → Image Recognition  
     - **Elemental MediaConvert** → Video Transcoding  
     - **Lambda Functions** → Custom processing tasks (e.g., extracting key frames from videos)
     - **AWS Batch & EKS Cluster** → For high usage and intensive process and custom use case, AWS batch for orchestrate the batch and EKS cluster for running the workload.

**7. Output Handling**  
   - Step 7.A:  
     Processed files are uploaded to the S3 bucket `S3_OUTPUT`.  
   - Step 7.B:  
     The processing stack sends process-related information (e.g., `processDuration`) to the SNS topic `SNS_NOTIF`. This step runs in parallel with 7.A.

**8. Output Metadata Generation**  
   - Step 8.A:  
     When processed file uploaded to `S3_OUTPUT`, and event generated and triggers the Lambda function `LAMBDA_OUTPUT`, which generates metadata for the processed file.  
   - Step 8.B:  
     `SNS_NOTIF` sends `processDuration` data to `LAMBDA_OUTPUT` to enrich the metadata.

**9. File Distribution**  
   - Step 9.A:  
     Files in `S3_OUTPUT` are copied to Amazon CloudFront (CDN) for global access.  
   - Step 9.B:  
     Metadata is sent to `DYNAMODB_OUTPUT`.
     
**10. User Access** 
    - Step 10.A:  
      Users can access processed files via CloudFront.  
    - Step 10.B:  
      Files can also be downloaded directly from `S3_OUTPUT`.  
    - Step 10.C:  
      Processed file metadata can be accessed from `DYNAMODB_OUTPUT`.

---

## AWS Services Used

- **S3**: File storage (`S3_INPUT` and `S3_OUTPUT`)
- **EventBridge**: Event routing
- **Lambda**: File classification, metadata generation, task orchestration and file processing.
- **SQS**: Job queueing
- **DynamoDB**: Metadata storage (`DYNAMODB_INPUT` and `DYNAMODB_OUTPUT`)
- **SNS**: Notifications
- **CloudFront**: File distribution (CDN)
- **Textract, Rekognition, MediaConvert**: Specialized file processing
- **AWS Batch & EKS Cluster**: Batch processing with Kubernetes running the workload.

---
---

# Questions and Answers:


This document outlines my approach and solutions for designing and implementing scalable, reliable, and maintenance-less infrastructure for a data processing system handling **5TB/day of various file types**.

---

### 1. **What architecture is suitable for the requirement? How can it be scalable, reliable, and maintenance-less?**

*Answer:
**Architecture Overview:**
I propsed an architecture with a serverless, event-driven, and highly scalable data pipeline. designed to handle 5TB of daily incoming data. Let we separates the data ingestion, classification, processing, and export stages. 
Decouple the classification stage and processing stage with Amazon queue service (SQS), to manage high amount of incoming data by buffering incoming data and avoid overloading the system. The architecture leverages as much as possible AWS managed services to minimize operational overhead.

**Key Features of the Architecture:**

**A. Data Ingestion and Event Triggering:**
Incoming data (images, media files, 3D files, and PDFs) is uploaded to an S3 bucket (`S3_INPUT`).
An EventBridge rule triggers a Lambda function upon new file uploads, ensuring an automated and asynchronous start to the processing pipeline.

**B. Data Classification:**
The triggered Lambda function (`LAMBDA_CLASSIFY`) classifies the uploaded files into their respective file types (e.g., image, video, 3D file, or PDF) and sends them to corresponding SQS queues for further processing.
Metadata for each file is stored in a DynamoDB table (`DYNAMODB_INPUT`), providing a centralized repository for tracking.

**C. Data Processing**:
- Separate SQS queues (`SQS_DOCUMENT`, `SQS_3D_FILE`, `SQS_PICTURE`, `SQS_VIDEO`) decouple processing tasks to allow for horizontal scaling.
- Dedicated Lambda functions based on files type to classify the processing_option:
Documents (PDFs): Utilize Amazon Textract for classification, text extraction, and semantic analysis.
3D Files: Perform rendering, optimization, and simulations.
Images: Use Amazon Rekognition for image recognition, resizing, and format conversion.
Videos: Leverage AWS Elemental MediaConvert for transcoding, encoding, and caption generation.

**D. Post-Processing and Export**:
Processed files are uploaded back to another S3 bucket (`S3_OUTPUT`).
A final Lambda function (`LAMBDA_OUTPUT`) sends events to EventBridge for post-processing notifications and updates metadata in DynamoDB (`DYNAMODB_OUTPUT`)`.
Files are distributed via CloudFront CDN, ensuring low-latency access for users.

**E. Monitoring and Alerting:**
Turnaround Time (TAT) and performance metrics are monitored using Amazon CloudWatch. Metrics and logs are configured for all services, including Lambda, S3, SQS and processing stack.
Alerts and notifications are sent via SNS when anomalies (e.g., delayed processing, high resource utilization) are detected.


**Scalability**:
- Serverless Services: Core components such as Lambda, SQS, and DynamoDB scale automatically with workload, handling peaks without manual intervention.
- Decoupled Architecture: By using SQS queues, processing is decoupled, allowing horizontal scaling of workers for each file type.
- CDN Integration: CloudFront ensures scalability for content delivery regardless of the number of users accessing processed files.

**Reliability:**
- Retry Mechanisms: SQS guarantees at-least-once delivery, and Lambda functions include automatic retries for transient failures.
- High Availability: AWS services such as S3, DynamoDB, and CloudFront are inherently highly available and fault-tolerant.
- Error Isolation: Each file type's processing is isolated, reducing the impact of failures in one type on others.

**Maintenance-Less:**
- Managed Services: AWS services such as Lambda, S3, and DynamoDB, Textract, Elemental MediaConvert and Rekognition, require minimal operational overhead since infrastructure provisioning and scaling are handled by AWS.
We also use EKS an Amazon managed Kubernetes cluster, even a Kubernetes expertise needed to run it, but it is much easier to managed than self-managed Kubernetes clusters.
- Event-Driven Design: The architecture reacts to events, eliminating the need for manual orchestration.
- Automation: Automation of monitoring, notifications, and error handling minimizes ongoing maintenance efforts.


---

### 2. **What monitoring strategies would you implement to ensure proactive system stabilization and effective auto-scaling?**

*Answer:*
Here is my proposal for proactive monitoring and auto-scaling:
**Monitoring Strategies**:

**A. AWS CloudWatch for Metrics and Alarms:**
- CloudWatch Metrics will be used to monitor critical system components such as AWS Lambda, SQS, S3, EKS, Rekogntion, MediaConvert, etc. Important metrics to monitor:
    - Lambda: Duration, Invocations, Throttles, Errors, and Concurrent Executions.
    - SQS: Message Queue Depth, Number of Messages Sent/Received.
    - S3: Bucket size, number of objects, and data retrieval request metrics.
    -  EKS Cluster: CPU and Memory utilization
    - Rekognition: SuccessfulRequestCount and `ThrottledCount`, Reference: https://docs.aws.amazon.com/rekognition/latest/dg/rekognition-monitoring.html
    - MediaConvert: Operation metrics, Queue metrics and Job metrics. Reference: https://docs.aws.amazon.com/mediaconvert/latest/ug/cloudwatch_metrics.html 
    - Textract: SuccessfulRequestCount, ThrottledCount. Reference: https://docs.aws.amazon.com/textract/latest/dg/cloudwatch-metricsdim.html 
    - CloudWatch Alarms will be set up for key thresholds (e.g., high memory usage, high message queue depth, or Lambda function errors) to trigger notifications via SNS (Simple Notification Service) to the infrastructure team for immediate attention. We can also integrate the alarm with communication platforms such as Slack.


**B. AWS CloudWatch Logs:**
- CloudWatch Logs will aggregate logs from Lambda, SQS, processing stack services (Textract, Rekognition, AWS Batch, EKS clusters, etc.) Logs will include application-specific details, such as errors, request processing times, or status updates for individual tasks.
- Log Groups and Log Streams, logs will be organized based on service components, making it easier to analyze logs from different parts of the system.
- Using CloudWatch Logs Insights, queries can be written to analyze logs and detect anomalies, such as slow processing times or high error rates.



**C. Use 3rd Party Monitoring and Logging**
We can also use third party monitoring for more comprehensive monitoring and logging if we find any limitation on AWS Cloudwatch for our use case. We can use 3rd party products that specialize in monitoring and logging, for example: Datadog, Prometheus and Grafana for monitoring. Splunk or Elasticsearch (ELK stack) for logging. 


**D. Set-up Pagerduty for Incident Handling**
We can define and set up priority for each alert, and route all alerts to Pagerduty to ease Incident handling management and escalation process.


**Proactive System Stabilization and Autoscaling:**
- Auto Scaling for EKS:
        - Deploy Horizontal Pod Autoscaler (HPA) with custom metric from AWS SQS to autoscale pods.
        - Install cluster autoscaler to autoscale EKS nodes.
- CloudWatch Dashboards: Centralized dashboards will provide an overview of system health, including real-time metrics such as CPU, memory, and message queue length, allowing engineers to detect early signs of instability.
- Alerts and Notifications: CloudWatch alarms tied to SNS will send alerts for any critical issues (e.g., high error rates or task failures), prompting the team to take action before the issue impacts users.

---

### 3. **What are the potential bottlenecks that might occur in the below architecture? How would you go about diagnosing and resolving these issues?**

*Answer:*
I think the potential bottleneck would be:
- Lambda function `LAMBDA_CLASSIFY`.
- Lambda function `LAMBDA_OUTPUT`, this Lambda will wait for data from `SNS_NOTIF` and event data from `S3_OUTPUT`, the event from `S3_OUTPUT` probably will arrive later than because data from SNS, because event from S3 will only be sent after the upload process complete.
 - 
---

### 4. **There is a big infrastructure; what’s the optimized cost plan?**

*Answer:*
For cost optimization, I propose several strategy:
- Monitor and Analyze cost:
    - Use AWS Cost Explorer to identify storage trends and optimize resources.
    - Set up AWS Budgets to monitor S3 spending.
    - Enable AWS CloudWatch metrics to track object-level usage and optimize accordingly.
    - Apply tagging to all AWS resources to improve cost monitoring and analysis.
- Use spot instance for EKS cluster worker node.
- Use different S3 storage class to optimize cost:
    - S3 Standard: For frequently accessed data.
    - S3 Intelligent-Tiering: Automatically moves data to the most cost-efficient storage tier based on usage patterns.
    - S3 Standard Infrequent Access and S3 One Zone-IA: For data accessed less frequently but still needed quickly.
    - S3 Glacier Flexible Retrieval, Glacier Instant Retrieval, or Glacier Deep Archive: For archival and long-term storage with varying retrieval speeds.
    - Set up S3 Lifecycle Policies to automate moving objects to cheaper storage classes. For example:
        - Move file to S3 Standard-IA after 30 days.
        - Move file to S3 Glacier after 90 days.
- To optimize cost for Lambda usage, here are some strategy that can be used:
    - Optimize code execution time
    - Use smaller package
    - Use AWS Lambda Power Tuning (an open-source tool) to find the optimal balance between memory and execution time for your workload. Reference: https://github.com/alexcasalboni/aws-lambda-power-tuning
    - Use compute saving plan for Lambda, reference: https://aws.amazon.com/savingsplans/compute-pricing/        


---

### 5. **Sample IaC Project**
I have created a sample Infrastructure-as-Code (IaC) project to demonstrate my ability to meet the infrastructure requirements. 
- **Repository URL:** [https://github.com/tampubolon/data-pipeline](https://github.com/tampubolon/data-pipeline)

---

Thank you for reviewing my work. Please feel free to reach out for any further clarifications or questions.
