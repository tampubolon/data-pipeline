# data-pipeline
Data Pipeline on AWS

![Architecture Diagram](/Pictures/image.png)

My architecture can be also see here: 
[Architecture Diagram](https://viewer.diagrams.net/index.html?tags=%7B%7D&lightbox=1&highlight=0000ff&edit=https%3A%2F%2Fapp.diagrams.net%2F%23G1yeDgWl9MzScVbPJ5gEhNIkLw7Y2a9--B%23%257B%2522pageId%2522%253A%2522_bkS12qFeahq00A4bDJi%2522%257D&layers=1&nav=1&title=Jitera.drawio#R%3Cmxfile%3E%3Cdiagram%20name%3D%22Page-1%22%20id%3D%22_bkS12qFeahq00A4bDJi%22%3E7V1Zd%2BK4tv41Weueh7BsyxOPTKlKV6YTUqer6iXLYJG4C2zamAz166%2FkCVuSB0AeSJzTZxXIQgjtb2%2FtSVtnYLR6%2B%2BIa6%2Bdrx4TLM0kw387A%2BEySRB3I6B%2Fc8h606FLY8ORaZthp1zC1%2FsCwUQhbt5YJN6mOnuMsPWudbpw7tg3nXqrNcF3nNd1t4SzT37o2niDVMJ0bS7r1b8v0noNWCQB19%2BArtJ6eo69WlfAHroyod%2FhTNs%2BG6bwmmsDkDIxcx%2FGCV6u3EVzi1YsWJvjcRcbTeGYutL0yHxgrP%2B%2BfL9QZ%2FPLn68t2Yr9v%2Ftydh6O8GMtt%2BIvPJHWJxhua1gt6%2BYRfRk2zqGEKHi9v7r4%2FRA%2FQl87IzqgtNYS%2FBN57tLCb39Cb4wUS0NO1Y9meTylliP5Dv2MU%2FF9BXUe4pScpjEZWm0Y3inQ39I%2FI%2BgaykdWm0Y0i3Q2%2Fi2adbmS1aQo9Y%2FLTIuPTIvFp9B8YOltvadlwFPMEXuOFY3sjZ%2Bm4%2FvoD9L8LjJPhwlouE%2B3aYCCKKmrfeK7zGyaeLPw%2FjAxj8wzNcNgX6HoW4pcrYwaXd87G8izHRs9mjuc5q0SHwdJ6wg88Z41ajfDdHIEXoi8YPnurJXovhjMNJYEoRe9D5OCvNDbr4GctrDc8jyHirDV%2BuHp7wlKoZ7xu5J4LN87WncPLOZ7PEL0NXqV7bUAMziQnRWyB5g7fEk0hZ32Bzgp67jvqEku6kMtDOadEXP%2B6kxqaHjQ9J%2BRF1GaEcuopHnnHyehFyMx7MLakUSwHTSTawreO6z07T45tLCe71qHrbG0zJu2uz5WDieYT5x%2Foee8hdYyt56RJB98s70fi9U88FIJs8G78Fo7sv3lPvLmDroV%2BN0aC3xaAL5K4Uh6NPMN9gl7eSkhBR%2Fzzc0npwqXhWS9pyc8iTPjROyy1dhDQxDQEQASBaIhgpuGnkoKaGEjRCCwp%2FfRAAbCpgQaua7wnuoVSNXvCAvE9qpA7L7I%2FEFL90YtgBjvQxot7OI5BtHueJI4RWN33H8k3iZHw291Q%2Frv35LsjmCJASN6ylmUepR7mUQn5qevlmOdozIe8VRbzuqrl9%2B%2FLef0r4pGDlLirwfVwPHgcXQ2m08uLn50u9%2BF0uckY7Uk7yfHRdbmlsZqZBh99TpFbps%2BpFI9PXqAveYbIcEbCOYfj3Y6fPwY%2Fa6KiDT8NP0MM8FmAbi5MDUjFummmFkGn3Fag3Ja1DNVKdNt9VVKg7KeSFvSvRsUUZWr%2FmULbxKsXbEPU7rNdI46WhO166RgYrpKApBksuQNhkvhSK41cSjKRAmxlmWbAJHBj%2FTFmsVxK72JjJrxyWTR0MIdDnsVe3fLS51zoCYIupWgXQfVI6ymyAMJRSceDs1hsoHdGSisesFAaEWBtFTxqScEDeAue43YhWrd8cK2nJ7REknAVKNUtZlCFJ4MCgWBQ%2BTgGDYfRamNIjaIlZfiPf94Mrm%2FHw%2BIYDg9jgqnwVq2mMrRO0DPfbWPlPJozWrOWJhoY6qgddTctuNPGbcfmpHwqclpIxx6vpPIp0cqnXhnb683K7p24%2FpmS1i33iEYc1hbh3acVM89xkaIloC8wTMOjhTdCrFed3MY034QmImWrhvyUZD9%2BLCYT9p0KlJ5CMZkYxWmSXAaEiugjScUCefrf6eP4dvT9enLzicTx5t8NLYjH%2FYEmi5UKYtJFLyk6LYjVCDhJkPTB8SD5cvk2nw%2BgPNYXv%2F7652X26%2B7b%2FXkMyXplcZb4JETbYfJUYgjUvvJj8t%2Bh%2FPLjrwm0vv17fjW%2B%2Fjvch5qSn1J28CTFn2D8eHF5Ncnlu45hq2FYPa05yaBOhmVjVm1Wd2qZ3Rsl9RXzek3h5L5EaAKakh4iI5zMywyTaHcZU6rcXY4evt9POhlStwxRpeZlSCMZWlzZXinL9nJNbK%2BS2RpyT%2B7v%2Fog4TtVCQCknBP53OZ7cdiKgbr1fF%2BsUAWyENKNGfPT4X%2BnkNu5%2B%2BANz0sQUMItz0tL9ZV0hkFhBAFBqxlvYQTWtULbE6whK6LeD68Gv2xvU6WHy4%2BF%2BMMpwbRGg6nKPUm2tyT0SxIGuj88%2BS%2B4RdpG7xtzLY%2B49TofIQEuJbDFy29eQecTUyE%2FKf1FKvDJ%2FZuQGKLRQqtEEqK1bFIg8d0kgAg9lD4mIAuinRwKgJyT%2BiLllnBk5QD1grt%2Bn1A5qwGVN%2FrKWoal%2FStKJFwprQFNNbhhOaNrXjhKFyEjZfS1Xw4i9%2BJ9R8lUfUZBKQjrCft0RBUkut3Hzgll2mBKrwSkAqv9unejBeZCJMUAdRHn9FvgLw%2BeZJ8NGS2OzsRZIO%2FeV9vyDYcHXZ1hzaaC%2FPlsenK4Nn%2FKvSNlOg5qHoi0SZBIjxTuZACIxEkBUDgkgeTK3FsI94MQeSZgEtsup004SQMO0y3bg86fdFK4MG1nE6EMDtBW8b6zNaVNPpU3ceqkHGgmwHa7GRVGyYmO1MWcgezqNGH91rDN36%2Bu4dT4ps6gO%2BnA%2FwHVcQL%2BEUzw8dJ8T8u384SfhD%2B%2FO1h%2BsKvTVOC07rgrHStSu1SEORIr12r2Jlc29iXwiLRGSoBF%2FSR3r3G%2FXOjdztLx%2BZaEsfQB3R9FxykKJ5LBQWchNEu3UhU5d%2BGzqAvtcV63qQpTb%2BeHFq152%2B5NaJV4byqxsMX0aqznAnk4z5UlbTJ92%2BfSieZdQT4iTcZ160qknn0s9kVLKiSw3r5wIpZn3bnxR9cmTjuc7nv%2FgPC9GR4sa43gpk%2BM3a8PmHKm2VttlmdSQ4KvbGqAGUeC5sQB1Tu0B%2FlS7h2i5Xct%2BOmmiyaBxomVH%2BfgT7XbtWSvrz%2BkzmyI0Trdsi4Y%2F3S5X%2BF4hSbiHc%2BfJtk6ffDqjjlK95KPrXFUpK%2F1PnTLFVAWwal%2FVm4CVbYfwpxnSgfFyoc9cOO7K8E6aehqjMnXNtKtzm3twDXszd0wsMvG0JWFiB29PmIZ641telL9WCw3DpGP0mW8QL8uFa6xOnIBa4wSkK%2FNWKECNdaCnCF%2BgDd3T1zn7ctP0k2khem3Mny0bbqjl6txknZvsrHk32cvqFTHh43zpbM1Hx3408A2qPNhT7kU12PLK%2BNXpNJPp7fHrdoU0EYo3C2maIFZJ8haWxUUAu7hAOoTAouefrQt7240%2FEgfakLaDwLIdZI1VG0mpTHaeVLY7zwORuWAtrk8d9Gu4ppEICEhJ%2BTWNyP68LzVhH%2B9qpOpueyHGOHdRD8SOO6THsnJIstrmAN8GvhO18Z4tpqmTJm96eUGKej1BSFew7wFBPoSGmRSj6jAXZpEEmixNiYQYVxgKcNR27Ll%2FoKS3eFEgt4eMo%2F5lhkoPVPFxayXb8ooNoajAlWqs8BZvzzbrtHlUKpwe289XE1z%2FfXCFvvV6Mr4cjG5v%2Fje5518Qvgvad9bIqVgjcAlXaArG8nEFTcuYhz5ePv4CmbjjU9Lo8%2Ba1GiRKict74qp695Nvt19uLh8ufRFUnHrXngKwLvwdB8WauImHInwLCsorpfMtsWv1%2B80I033apW51u8An2AV4pm5RzK9GN741JvWzI9s75fAb4nVhdPV9%2BjC5LyXuO9btWLcFrAt%2Fc3IfizJx7S0rOldvCdXs7Iay1YGAUBycY4xC979znTncbPzsPmHqGfPfBZG73NpBH%2FV%2BOBEoxNVfNISkCFa1OLlVMRNDR9j2PFQ%2Ffh6zTMIV%2Bg9r8lqphO9ZFOR%2BpPzv7bciByMvFiys78v1jlg26Er4tqY308eb24fLjNMhrbUtN3Yzl4uIWl8kTikj2veiY8KFhuWulbuMia4cL2Va3n5%2FyLwTuNMwOw2zfRomV%2BNQ6xNhyOiiv6aUTP34DDApS8mcoj0%2BJ3qRTu7K1CyOnsY60F3HWyrljDWD0hrP0fOy7IWz52Q%2Bix6tlzlKxVKk%2B1Up0vrxpzsygXDlGGYDfLGKr%2B%2FuMMjCICGq5T4Dg6yrvivL9uyzUuazzaq5X2V7vp8xRe3p%2BO%2Fi4iTMLCHDgbO3jUXu0tRIFScH9PfLOOFFaEEQB6dIaEkVDya0kj9S1YRmaV8dR8ciWNUIm%2Fdgnsa%2B0GZ5mhV7P4rUWXl%2Bsn52dKLfSfjVdDV9HYuiyD0gJa7jPRgqgBy3XqiwAnYdVI6BikRc3KzoCg%2BoiLKkkOPWChUx2go7rFSGFTRwGiuAE1iosE%2FlYGFFgzqw8ARLX9IrESx9Sa8ZKyyHRzZWQsO7pF4qsfRSfHHbSeilkpjWO3aXbu6tahAjKf26qbyfqsGJyqPRKVCZvOnrYCqLcr9oqKrpLHKX%2FB%2BJoUsQ6Ahal7yBlx%2BtpWpp7Z9SCu%2BH3N0J%2BTPa2PncSUodTUqeLvty%2BTafD6A81he%2F%2FvrnZfbr7tt9cE9mc7Yo6V4gqV4aQORIas0nk0TmzQGctMRe%2BkRbxUpi4XG2KHWhLXKIpD0gs3vK%2BzAIHymo%2BTpRUcw%2Ba8IpsCzAF%2BgnGTYdYN6u%2FaomLpxD6yUogLjPlOqLOIeRcIgXb2Et4aY1MyOX7MUyUPcJJvDQtTB3dkHKMoFy9s0VzFC5SO4r%2FGq7Syxtk2uwXLDs9dbbwVjwHLyWySzlDZGlnFtL6KMCRNdJbZRRsyjeZZLwIPcLjuhg6adEvuC%2Bie6imgGX7xvoJsVcOi%2B9RBZiQ6VZBGE4ufCtqqpLswCqkqrMECE6AyIah4xSpiqfLT5iOg3%2BxgeWhoOH0dcTyyCeGX5WK1WLR9EVIJ8V5BBTdGVQP3u3kIFOxFO1qAxjLSdTs%2B22gmRx8LhH3nB7SL0BNJ0ngiLJoFo607niukRfU18znbMT6EoLeVC21CCW%2Bvg3zLE6kKOOF59cylR5%2BU%2Fae4ahQoOXyVeAR7hK2sINZrTvpE9XJz4K%2FbtSLjH2GYl7akUqD3s%2Fyz7Jd7jGo1C4EuaxmNk1%2Bl7YxYLGn3iMVvRRwSMCIp7PuA6ApS2Tfhp%2B0MnWhbgjBf%2BxkJLAaqnDotJewuqTIAsQDrnmkVWFGXYs1EAnlBiVTfW2QSf7XpnmoCP3Bh14aPCoZIYaQxtihTSqA0924f8mwVNCm%2F584FGIksqqRBeyqhc82TcONAcepYMOQ5MWZEA6IUQaPfXuWyUKE3ToaQd6iGo8qkz7pOvFTonaiR122oEdSvLISsPoKXNjboeelqCHSP8X6Kqt9WIn21BvrQtI7VxAjGC8LBByCYGtacHURlNe60x5pmhSCUeQzkjmqNUcy7mrli0pFo47h%2Ba5j4Zzw%2Fxnu%2FECzMSrFCEFN7pPs%2F%2FDxY%2FQy%2Bif%2FwSdfMQtjJW1fA%2B6foXLF4hJmngefn0wvLsylolnL4ZrGehfRH%2FD2yKqF%2FSbG2tGlyX0EJ7ON2tjjpOOqOeOu37G9%2F0EKU1BG0bneQhI3BxjMnpm2aYPCPwwyoIKnnj4GkO0hCtyzRD9ndf017w6rpmeWDzW%2BSuc%2FbbQcHjMAL%2FnIYJS%2Ffwr1fwx4lUML1ZDr2fG%2FPeTn%2BZ7TlBMUsSAWMkX%2F0n8DBPOnaAWz7n3bM1%2F2zhI63%2FcwlW7o8Uj%2BybImdsvMZ1kv6wtLZRqJQXUYZguFpCR4OPhhip1Fd6Rkog45SCptJLEkkSVhVilNpr2erePsfNT9PQBe1WjtaB697E2Gvd655Nmo4dwSoN%2B0%2BjJLrBeFixFtcGyEpg4JyuVOTmw%2F1yOOxfA5wek8sSnJcLM%2B19p9GEZLva97ntvMY9qfEyO43Dx%2B4lUrQyOE7XzkA4uYIlsnVYV1Qz4O3Vzzcc6L3QkKxNhFVGm84JFlgOKy2khNi%2BXyPYf%2F7wZXN%2BOh6eZBm6%2B28bKeTRnBF1L30Z1XD6sAIgiE8wDHppEE13POcF6HM2zXdoxQUdXt9%2FHF%2Fe3N6dG7vkuaZt9ykOtl96ssHvNuf8g2094tMQfOev3FuzXSQWz8cmMxjcF39ppuMltsU8cGdCiwgAJlunXquCq1OLXenN0uk5D%2FGz%2FOg2scjBZd0pTNT8KLpnO3VoKaz%2BE51BpUHC%2FVZo9zwrrgfZE%2BSxVjk3lcPc32ItOhy9%2FXTW8CJZXyCp%2F6RFLF96QCO%2BUUl2RPzauKixUHxyra3x3i4%2F1tcPkJFfkw9fVP049jYtRRLlZLG8Sq65%2BZZttFJRqbLPV9fR22xMkDgJbyt2EOW659e24%2FkfRlmi8JzqE6M4U9VRVpbgkW6YQB30x9xPoRTALrqJbPr5syt5HpE3n1V4GJVV254%2BxHWNaLrKjl3ihkS278r3mue6Xky%2B0cqTVrWWArLDSSmVxKbmEl2XfAEsXE6%2FKBKXuJwAML12tcU25jbmBXVS8HH4URsp7vehp4zm%2Ffid92DUztOIQb73oaeNBv34ne9joUYli9Y2jJzcbsMtL7vKSu7zkHRyL85L7vREHwVd9XrIkkVVWlHKSqLK85CisXt8NbyZcGNvljg7FLp7GfPBEHqdEEKF0yXSFvCaOGqpip7vGspQqpfIhrrzG6EyUIj%2F4Xk5FIulc3SV%2BbDpn2zRHZ6jmKyh0%2F0tm9h3LIVfZYUuWQE%2FDmINMF%2FV%2BmuaM87isan6VKZdatmmSt2fTdfhqBMsFUe39A8KEuIgLKGLDMNnXBilUBYvhImWdIoBPQVZzI7ZrLfQn3F%2BSQie21kp%2B5iWeFZM%2FK%2Fgz9qPRwp21hjhHEr0cuHNMlDk2MbHRFFqr1wYiob3F8Z8HY7XezpAgsz80bOQema%2FBMBhYqV8HAAe9dR1MmJ1KgrNGrx0T4h7%2FDw%3D%3D%3C%2Fdiagram%3E%3C%2Fmxfile%3E#%7B%22pageId%22%3A%22_bkS12qFeahq00A4bDJi%22%7D)



## Data Pipeline Architecture Workflow

1. Human users or machines upload media files to the S3 bucket `S3_INPUT`.

2.  Once a file upload is complete, an event is triggered.

3. Event Processing
   - EventBridge routes the event to the Lambda function `LAMBDA_CLASSIFY`.
   - `LAMBDA_CLASSIFY` determines the file type (e.g., document, 3D file, image, or video) and processes the event data to:
     - Forward the event to the appropriate SQS queue.
     - Generate metadata for the uploaded file.

4. Queue and Metadata Handling
   - Step 4.A:  
     `LAMBDA_CLASSIFY` forwards the event data to the relevant SQS queue:  
       - Document files → `SQS_DOCUMENT`  
       - Image files → `SQS_PICTURE`  
       - 3D files → `SQS_3D_FILE`  
       - Video files → `SQS_VIDEO`
   - Step 4.B:  
     Metadata for the uploaded file is sent to DynamoDB `DYNAMODB_INPUT`. This step runs in parallel with 4.A.

5. Job Queue Processing  
   - Files in the SQS queues are processed based on their `processingOption`, which defines the required actions for the uploaded file.  
     Examples:  
     - Document files → Classification, Text Extraction, Semantic Analysis  
     - 3D files → Simulation, Rendering, Render Optimization  
     - Image → Image recognition, Resize, Convert Format
     - Video files → Transcode / Encode, Extract Key Frame, Caption Generation
   - The `processingOption` is an input provided by the user during file upload (Step 1).
   - `LAMBDA_CLASSIFY` forwards this information to the appropriate processing stack along with the S3 file path (`S3_INPUT`). Procesing stack use the S3 file path to download the input file.

6. File Processing  
   - The processing stack downloads files from `S3_INPUT` and processes them using AWS services such as:  
     - **Amazon Textract** → Text Extraction  
     - **Amazon Rekognition** → Image Recognition  
     - **Elemental MediaConvert** → Video Transcoding  
     - **Lambda Functions** → Custom processing tasks (e.g., extracting key frames from videos)
     - **AWS Batch & EKS Cluster** → For high usage and intensive process and custom use case, AWS batch for orchestrate the batch and EKS cluster for running the workload.

7. Output Handling  
   - Step 7.A:  
     Processed files are uploaded to the S3 bucket `S3_OUTPUT`.  
   - Step 7.B:  
     The processing stack sends process-related information (e.g., `processDuration`) to the SNS topic `SNS_NOTIF`. This step runs in parallel with 7.A.

8. Output Metadata Generation  
   - Step 8.A:  
     When processed file uploaded to `S3_OUTPUT`, and event generated and triggers the Lambda function `LAMBDA_OUTPUT`, which generates metadata for the processed file.  
   - Step 8.B:  
     `SNS_NOTIF` sends `processDuration` data to `LAMBDA_OUTPUT` to enrich the metadata.

9. File Distribution  
   - Step 9.A:  
     Files in `S3_OUTPUT` are copied to Amazon CloudFront (CDN) for global access.  
   - Step 9.B:  
     Metadata is sent to `DYNAMODB_OUTPUT`.

10. User Access  
    - Step 10.A:  
      Users can access processed files via CloudFront.  
    - Step 10.B:  
      Files can also be downloaded directly from `S3_OUTPUT`.  
    - Step 10.C:  
      Processed file metadata can be accessed from `DYNAMODB_OUTPUT`.

---

## AWS Services Used

- **S3**: File storage (`S3_INPUT` and `S3_OUTPUT`)
- **EventBridge**: Event routing
- **Lambda**: File classification, metadata generation, task orchestration and file processing.
- **SQS**: Job queueing
- **DynamoDB**: Metadata storage (`DYNAMODB_INPUT` and `DYNAMODB_OUTPUT`)
- **SNS**: Notifications
- **CloudFront**: File distribution (CDN)
- **Textract, Rekognition, MediaConvert**: Specialized file processing
- **AWS Batch & EKS Cluster**: Batch processing with Kubernetes running the workload.

---
---

# Questions and Answers:


This document outlines my approach and solutions for designing and implementing scalable, reliable, and maintenance-less infrastructure for a data processing system handling **5TB/day of various file types**.

---

### 1. **What architecture is suitable for the requirement? How can it be scalable, reliable, and maintenance-less?**

*Answer: [
    **Architecture Overview:**
I propsed an architecture with a serverless, event-driven, and highly scalable data pipeline. designed to handle 5TB of daily incoming data. Let we separates the data ingestion, classification, processing, and export stages. 
Decouple the classification stage and processing stage with Amazon queue service (SQS), to manage high amount of incoming data. The architecture leverages as much as possible AWS managed services to minimize operational overhead.

*Key Features of the Architecture:*
A. Data Ingestion and Event Triggering:

Incoming data (images, media files, 3D files, and PDFs) is uploaded to an S3 bucket (`S3_INPUT`).
An EventBridge rule triggers a Lambda function upon new file uploads, ensuring an automated and asynchronous start to the processing pipeline.

B. Data Classification:

The triggered Lambda function (`LAMBDA_CLASSIFY`) classifies the uploaded files into their respective file types (e.g., image, video, 3D file, or PDF) and sends them to corresponding SQS queues for further processing.
Metadata for each file is stored in a DynamoDB table (DYNAMODB_INPUT), providing a centralized repository for tracking.

**C. Data Processing**:

Separate SQS queues (SQS_DOCUMENT, SQS_3D_FILE, SQS_PICTURE, SQS_VIDEO) decouple processing tasks to allow for horizontal scaling.
Dedicated Lambda functions process files based on type:
Documents (PDFs): Utilize Amazon Textract for classification, text extraction, and semantic analysis.
3D Files: Perform rendering, optimization, and simulations.
Images: Use Amazon Rekognition for image recognition, resizing, and format conversion.
Videos: Leverage AWS Elemental MediaConvert for transcoding, encoding, and caption generation.

**D. Post-Processing and Export**:
Processed files are uploaded back to another S3 bucket (S3_OUTPUT).
A final Lambda function (LAMBDA_OUTPUT) sends events to EventBridge for post-processing notifications and updates metadata in DynamoDB (DYNAMODB_OUTPUT).
Files are distributed via CloudFront CDN, ensuring low-latency access for users.

E. Monitoring and Alerting:
Turnaround Time (TAT) and performance metrics are monitored using Amazon CloudWatch. Metrics and logs are configured for all services, including Lambda, S3, SQS and processing stack.
Alerts and notifications are sent via SNS when anomalies (e.g., delayed processing, high resource utilization) are detected.

**Scalability**:
- Serverless Services: Core components such as Lambda, SQS, and DynamoDB scale automatically with workload, handling peaks without manual intervention.
- Decoupled Architecture: By using SQS queues, processing is decoupled, allowing horizontal scaling of workers for each file type.
- CDN Integration: CloudFront ensures scalability for content delivery regardless of the number of users accessing processed files.

**Reliability:**
- Retry Mechanisms: SQS guarantees at-least-once delivery, and Lambda functions include automatic retries for transient failures.
- High Availability: AWS services such as S3, DynamoDB, and CloudFront are inherently highly available and fault-tolerant.
- Error Isolation: Each file type's processing is isolated, reducing the impact of failures in one type on others.

**Maintenance-Less**:
- Managed Services: AWS services such as Lambda, S3, and DynamoDB, Textract, Elemental MediaConvert and Rekognition, require minimal operational overhead since infrastructure provisioning and scaling are handled by AWS.
We also use EKS an Amazon managed Kubernetes cluster, even a Kubernetes expertise needed to run it, but it is much easier to managed than self-managed Kubernetes clusters.
- Event-Driven Design: The architecture reacts to events, eliminating the need for manual orchestration.
- Automation: Automation of monitoring, notifications, and error handling minimizes ongoing maintenance efforts.

]*

---

### 2. **What monitoring strategies would you implement to ensure proactive system stabilization and effective auto-scaling?**

*Answer: [Provide your answer here]*

---

### 3. **What are the potential bottlenecks that might occur in the below architecture? How would you go about diagnosing and resolving these issues?**

*Answer: [Provide your answer here]*

---

### 4. **There is a big infrastructure; what’s the optimized cost plan?**

*Answer: [Provide your answer here]*

---

### 5. **Sample IaC Project**

I have created a sample Infrastructure-as-Code (IaC) project to demonstrate my ability to meet the infrastructure requirements. The repository includes essential configurations and code snippets, focusing on scalability, reliability, and maintainability.

#### **Repository Details:**
- **Repository URL:** [Private GitHub repository link]
- **Invited Collaborators:** `@yota345` and `@tanvlt`

Please note that the project demonstrates core concepts and skills rather than a complete implementation. The total time spent does not exceed two hours.

---

Thank you for reviewing my work. Please feel free to reach out for any further clarifications or questions.
